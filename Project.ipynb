{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caeb5e35",
   "metadata": {},
   "source": [
    "# Load Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aec54bd-fb7e-4af8-9cfc-cc1c317a72d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zengo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2369fdf-93e9-498c-8f7f-b79c159c1995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zengo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zengo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = {\n",
    "    0: (\"actinic keratoses and intraepithelial carcinomae(Cancer)\"),\n",
    "    1: (\"basal cell carcinoma(Cancer)\"),\n",
    "    2: (\"benign keratosis-like lesions(Non-Cancerous)\"),\n",
    "    3: (\"dermatofibroma(Non-Cancerous)\"),\n",
    "    4: (\"melanocytic nevi(Non-Cancerous)\"),\n",
    "    5: (\"pyogenic granulomas and hemorrhage(Can lead to cancer)\"),\n",
    "    6: (\"melanoma(Cancer)\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9d6dba-b422-4ba5-8932-4ec1ccca6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test set into X and Y\n",
    "train_path = \"dataset\\hmnist_28_28_RGB_train.csv\"\n",
    "test_path = \"dataset\\hmnist_28_28_RGB_test.csv\"\n",
    "\n",
    "train_set = pd.read_csv(train_path)\n",
    "test_set = pd.read_csv(test_path)\n",
    "\n",
    "y_train = train_set['label']\n",
    "x_train = train_set.drop(columns=['label'])\n",
    "x_train=np.array(x_train).reshape(-1,28,28,3)\n",
    "\n",
    "y_test = test_set['label']\n",
    "x_test = test_set.drop(columns=['label'])\n",
    "x_test=np.array(x_test).reshape(-1,28,28,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf29ef18-02b2-4af2-aa8c-b163d039d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba52c0c1-126d-40ba-9114-4286feb261f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 14, 14, 16)        64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 5, 5, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 1, 256)         295168    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 504103 (1.92 MB)\n",
      "Trainable params: 502983 (1.92 MB)\n",
      "Non-trainable params: 1120 (4.38 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb09f35-e6ca-4106-b9ef-3363b8c5d9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4607079029083252\n",
      "Test accuracy (%): 72.54118919372559\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of pre-trained model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0, batch_size=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy (%):', 100*score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c0e80",
   "metadata": {},
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d733962a",
   "metadata": {},
   "source": [
    "### Function to Make Pertubated Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def create_compromised_image(image, epsilon):\n",
    "  image = tf.convert_to_tensor(image.reshape((1, 28, 28, 3)), dtype=tf.float32)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(image)\n",
    "    prediction = model(image)\n",
    "    label = tf.argmax(prediction, axis=1)\n",
    "    loss = loss_object(label, prediction)\n",
    "\n",
    "  gradient = tape.gradient(loss, image)\n",
    "  perturbations = tf.sign(gradient)\n",
    "\n",
    "  adversarial_image = image + epsilon*perturbations\n",
    "  return adversarial_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865fb135",
   "metadata": {},
   "source": [
    "### Test Out Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(new_image, description):\n",
    "  #  Display the given image along with its predicted label and confidence.\n",
    "  pred = model.predict(new_image)\n",
    "  label = np.argmax(pred, axis=1)[0]\n",
    "  label = classes[label]\n",
    "  confidence = np.max(pred, axis=1)[0]\n",
    "  plt.figure()\n",
    "  plt.imshow(new_image[0]*0.5/255+0.5)\n",
    "  plt.title('{} \\n {} : {:.2f}% Confidence'.format(description, label, confidence*100))\n",
    "  plt.show()\n",
    "\n",
    "epsilons = np.array([0, 0.005, 0.01])*255\n",
    "descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n",
    "                for eps in epsilons]\n",
    "\n",
    "for i, eps in enumerate(epsilons):\n",
    "  adv_x = create_compromised_image(x_test[0], eps)\n",
    "  display_images(adv_x, descriptions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dd04bc",
   "metadata": {},
   "source": [
    "### Test Attck on multiple images and plot the accuracy for different epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = np.linspace(0, 245, 20)\n",
    "\n",
    "length = 20\n",
    "\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "\n",
    "for eps in epsilon:\n",
    "    x_test_compromised = []\n",
    "    for i, img in enumerate(x_test[:length]):\n",
    "        adv_x = create_compromised_image(img, eps)[0].numpy()\n",
    "        x_test_compromised.append(adv_x)\n",
    "\n",
    "    x_test_compromised = np.array(x_test_compromised)\n",
    "    score = model.evaluate(x_test_compromised, y_test[:length], verbose=0, batch_size=1)\n",
    "    test_loss.append(score[0])\n",
    "    test_acc.append(score[1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epsilon, test_loss)\n",
    "plt.title('Loss vs Epsilon')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epsilon, test_acc)\n",
    "plt.title('Accuracy vs Epsilon')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbfded",
   "metadata": {},
   "source": [
    "### Make Equivalent CSV file of Pertubated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e30dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images\n",
    "comp_path = 'dataset\\\\hmnist_28_28_RGB_0e055.csv'\n",
    "\n",
    "def make_and_store_pertubated_images(og_path, comp_path, epsilon):\n",
    "\n",
    "    og_df=pd.read_csv(og_path)\n",
    "\n",
    "    labels = og_df['label']\n",
    "    og_img = og_df.drop(columns=['label'])\n",
    "    og_img=np.array(og_img).reshape(-1,28,28,3)\n",
    "\n",
    "    # Create compromised dataset\n",
    "    compromised_img = []\n",
    "    epsilon = 0.055\n",
    "    for i, img in enumerate(og_img):\n",
    "        adv_x = create_compromised_image(img, epsilon*255).numpy()\n",
    "        compromised_img.append(adv_x)\n",
    "    compromised_img = np.array(compromised_img)\n",
    "\n",
    "    # Evaluate compromised dataset\n",
    "    score = model.evaluate(compromised_img, labels, verbose=0, batch_size=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy (%):', 100*score[1])\n",
    "\n",
    "    # Save as csv\n",
    "    compromised_img = compromised_img.reshape(-1, 28*28*3)\n",
    "    compromised_img_with_labels = np.concatenate((compromised_img, np.array(labels)[:, None]), axis=1)\n",
    "    comp_df = pd.DataFrame(compromised_img_with_labels)\n",
    "    comp_df.columns = og_df.columns\n",
    "    comp_df.to_csv(comp_path, index=False)\n",
    "\n",
    "# make_and_store_pertubated_images(og_path, comp_path, 0.055)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f128e",
   "metadata": {},
   "source": [
    "# Defence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bfb1d9",
   "metadata": {},
   "source": [
    "### Load Pertubated Images and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df=pd.read_csv(comp_path)\n",
    "\n",
    "comp_labels = comp_df['label']\n",
    "comp_img = comp_df.drop(columns=['label'])\n",
    "comp_img=np.array(comp_img).reshape(-1,28,28,3)\n",
    "\n",
    "# Evaluate compromised dataset\n",
    "score = model.evaluate(comp_img, comp_labels, verbose=0, batch_size=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy (%):', 100*score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d453ce23",
   "metadata": {},
   "source": [
    "### Mix Pertubated Images With Normal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee88c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_df = pd.read_csv(og_path)\n",
    "\n",
    "mixed_df = pd.concat([og_df, comp_df], ignore_index=True)\n",
    "mixed_df = mixed_df.sample(frac=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
